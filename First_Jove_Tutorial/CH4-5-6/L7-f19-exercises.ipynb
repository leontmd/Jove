{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You may use any of these help commands:\n",
      "help(ResetStNum)\n",
      "help(NxtStateStr)\n",
      "\n",
      "You may use any of these help commands:\n",
      "help(md2mc)\n",
      ".. and if you want to dig more, then ..\n",
      "help(default_line_attr)\n",
      "help(length_ok_input_items)\n",
      "help(union_line_attr_list_fld)\n",
      "help(extend_rsltdict)\n",
      "help(form_delta)\n",
      "help(get_machine_components)\n",
      "\n",
      "You may use any of these help commands:\n",
      "help(mkp_dfa)\n",
      "help(mk_dfa)\n",
      "help(totalize_dfa)\n",
      "help(addtosigma_delta)\n",
      "help(step_dfa)\n",
      "help(run_dfa)\n",
      "help(accepts_dfa)\n",
      "help(comp_dfa)\n",
      "help(union_dfa)\n",
      "help(intersect_dfa)\n",
      "help(pruneUnreach)\n",
      "help(iso_dfa)\n",
      "help(langeq_dfa)\n",
      "help(same_status)\n",
      "help(h_langeq_dfa)\n",
      "help(fixptDist)\n",
      "help(min_dfa)\n",
      "help(pairFR)\n",
      "help(state_combos)\n",
      "help(sepFinNonFin)\n",
      "help(bash_eql_classes)\n",
      "help(listminus)\n",
      "help(bash_1)\n",
      "help(mk_rep_eqc)\n",
      "help(F_of)\n",
      "help(rep_of_s)\n",
      "help(q0_of)\n",
      "help(Delta_of)\n",
      "help(mk_state_eqc_name)\n",
      "\n",
      "You may use any of these help commands:\n",
      "help(lphi)\n",
      "help(lunit)\n",
      "help(lcat)\n",
      "help(lexp)\n",
      "help(lunion)\n",
      "help(lstar)\n",
      "help(srev)\n",
      "help(lrev)\n",
      "help(shomo)\n",
      "help(lhomo)\n",
      "help(powset)\n",
      "help(lint)\n",
      "help(lsymdiff)\n",
      "help(lminus)\n",
      "help(lissubset)\n",
      "help(lissuperset)\n",
      "help(lcomplem)\n",
      "help(product)\n",
      "help(nthnumeric)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path[0:0] = ['../..','../../3rdparty','../../..','../../../3rdparty','../../../..','../../../../3rdparty']\n",
    "from jove.DotBashers import *\n",
    "from jove.Def_md2mc  import *\n",
    "from jove.Def_DFA    import *\n",
    "from jove.LangDef    import *  # for testing DFA actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def mkp_dfa(Q, Sigma, Delta, q0, F):\n",
    "    \"\"\"In : Traits of a DFA\n",
    "       Out: A DFA\n",
    "       Check for partial consistency of the given DFA traits.\n",
    "       If the check passes, make and return a DFA with a partial \n",
    "       Delta.\n",
    "    \"\"\"\n",
    "    newDFA = {\"Q\":Q, \"Sigma\":Sigma, \"Delta\":Delta, \"q0\":q0, \"F\":F}\n",
    "    assert(\n",
    "        is_partially_consistent_dfa(newDFA)\n",
    "    ), \"DFA given to mkp_dfa is not partially consistent. Plz check its components.\"\n",
    "    return(newDFA)\n",
    "\n",
    "def mk_dfa(Q, Sigma, Delta, q0, F):\n",
    "    \"\"\"In : Traits of a DFA\n",
    "       Out: A DFA\n",
    "       Check for structural consistency of the given DFA traits.\n",
    "       If the check passes, make and return a DFA with a total \n",
    "       Delta.\n",
    "    \"\"\"\n",
    "    newDFA = {\"Q\":Q, \"Sigma\":Sigma, \"Delta\":Delta, \"q0\":q0, \"F\":F}\n",
    "    assert(\n",
    "        is_consistent_dfa(newDFA)\n",
    "    ), \"DFA given to mk_dfa is not consistent. Plz check its components.\"\n",
    "    return(newDFA)\n",
    "\n",
    "def totalize_dfa(D):\n",
    "    \"\"\"In : Partially consistent DFA\n",
    "       Out: A consistent DFA \n",
    "       Given a partially specified DFA, make it total by \n",
    "       transitioning to state BH wherever the incoming Delta \n",
    "       has gaps. The returned DFA is structurally consistent.\n",
    "    \"\"\"\n",
    "    assert(\n",
    "        is_partially_consistent_dfa(D)\n",
    "    ), \"DFA given to totalize_dfa is not partially consistent.\"\n",
    "    if set(fn_dom(D[\"Delta\"])) == set(product(D[\"Q\"], D[\"Sigma\"])):\n",
    "        # It is already total!\n",
    "        return D \n",
    "    else:        \n",
    "        # We must introduce a BH state of not already present\n",
    "        # and proceed from there\n",
    "        incoming_Delta = D[\"Delta\"].copy()\n",
    "    \n",
    "        # Gaps in incoming_Delta's transition function are sent\n",
    "        # to the BH (black-hole) state\n",
    "        gaps_in_Tr = { (q,c) : \"BH\" for q in D[\"Q\"] for c in D[\"Sigma\"] \n",
    "                       if (q,c) not in D[\"Delta\"] }\n",
    "    \n",
    "        # We are gonna add a new black-hole-state.\n",
    "        # It must curl back to itself for every symbol in Sigma\n",
    "        bh_self_absorbent_moves = { (\"BH\", c): \"BH\" for c in D[\"Sigma\"] }\n",
    "\n",
    "        # Fill the gaps in incoming_Delta\n",
    "        incoming_Delta.update( gaps_in_Tr )\n",
    "    \n",
    "        # Add in the moves where the black-hole state curls \n",
    "        # back to itself\n",
    "        incoming_Delta.update( bh_self_absorbent_moves )\n",
    "        \n",
    "        # All updates required are accomplished\n",
    "        finished_Delta = incoming_Delta\n",
    "    \n",
    "        # See that we update D[\"Q\"] with the \"BH\" (black-hole) \n",
    "        # state; also return the fixed-up incoming_Delta\n",
    "        return {\"Q\"    : D[\"Q\"] | { \"BH\" }, \n",
    "                \"Sigma\": D[\"Sigma\"],    \n",
    "                \"Delta\": finished_Delta,\n",
    "                \"q0\"   : D[\"q0\"],          \n",
    "                \"F\"    : D[\"F\"] }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFA_B0 = md2mc('''DFA !! DFA for words beginning with 0's\n",
    "I : 0   -> F\n",
    "I : 1   -> B\n",
    "B : 0|1 -> B\n",
    "F : 0|1 -> F\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q': {'B', 'F', 'I'},\n",
       " 'Sigma': {'0', '1'},\n",
       " 'Delta': {('I', '0'): 'F',\n",
       "  ('I', '1'): 'B',\n",
       "  ('B', '0'): 'B',\n",
       "  ('B', '1'): 'B',\n",
       "  ('F', '0'): 'F',\n",
       "  ('F', '1'): 'F'},\n",
       " 'q0': 'I',\n",
       " 'F': {'F'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DFA_B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DFA_B0[\"Delta\"][('I','0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"226pt\" height=\"238pt\"\n",
       " viewBox=\"0.00 0.00 226.00 238.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 234)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-234 222,-234 222,4 -4,4\"/>\n",
       "<!-- EMPTY -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>EMPTY</title>\n",
       "</g>\n",
       "<!-- I -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>I</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"109\" cy=\"-84\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-80.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">I</text>\n",
       "</g>\n",
       "<!-- EMPTY&#45;&gt;I -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>EMPTY&#45;&gt;I</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.3048,-84C62.6909,-84 71.9407,-84 80.4103,-84\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.5976,-87.5001 90.5976,-84 80.5976,-80.5001 80.5976,-87.5001\"/>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"196\" cy=\"-146\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"196\" y=\"-142.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">B</text>\n",
       "</g>\n",
       "<!-- I&#45;&gt;B -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>I&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M123.7584,-94.5175C137.1319,-104.048 157.0656,-118.2537 172.6082,-129.33\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"170.9943,-132.4777 181.1692,-135.431 175.0568,-126.7771 170.9943,-132.4777\"/>\n",
       "<text text-anchor=\"middle\" x=\"150.5\" y=\"-119.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- F -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>F</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"196\" cy=\"-22\" rx=\"18\" ry=\"18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"196\" cy=\"-22\" rx=\"22\" ry=\"22\"/>\n",
       "<text text-anchor=\"middle\" x=\"196\" y=\"-18.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">F</text>\n",
       "</g>\n",
       "<!-- I&#45;&gt;F -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>I&#45;&gt;F</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M123.7584,-73.4825C136.2403,-64.5874 154.4369,-51.6197 169.4444,-40.9247\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"171.7323,-43.5921 177.8447,-34.9383 167.6698,-37.8915 171.7323,-43.5921\"/>\n",
       "<text text-anchor=\"middle\" x=\"150.5\" y=\"-59.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;B -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>B&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M192.0452,-163.7817C191.3731,-173.3149 192.6914,-182 196,-182 198.0162,-182 199.2933,-178.7749 199.8313,-174.0981\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"203.3347,-173.823 199.9548,-163.7817 196.3352,-173.7391 203.3347,-173.823\"/>\n",
       "<text text-anchor=\"middle\" x=\"196\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;B -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>B&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M189.6237,-162.8636C185.7535,-180.3779 187.8789,-200 196,-200 202.5984,-200 205.2387,-187.0463 203.921,-172.7944\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"207.3717,-172.2068 202.3763,-162.8636 200.4549,-173.2827 207.3717,-172.2068\"/>\n",
       "<text text-anchor=\"middle\" x=\"196\" y=\"-203.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- F&#45;&gt;F -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>F&#45;&gt;F</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M191.9395,-43.8066C191.5527,-53.5625 192.9063,-62 196,-62 197.9336,-62 199.1874,-58.7041 199.7614,-53.8504\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"203.2612,-53.9064 200.0605,-43.8066 196.2643,-53.698 203.2612,-53.9064\"/>\n",
       "<text text-anchor=\"middle\" x=\"196\" y=\"-65.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- F&#45;&gt;F -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>F&#45;&gt;F</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M189.0597,-43.1143C185.9952,-61.0956 188.3086,-80 196,-80 202.2493,-80 204.9482,-67.5201 204.0969,-53.1954\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"207.5574,-52.6501 202.9403,-43.1143 200.603,-53.4481 207.5574,-52.6501\"/>\n",
       "<text text-anchor=\"middle\" x=\"196\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x103f3d9b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotObj_dfa(DFA_B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFA_E1 = md2mc('''DFA !! accepts words that end in a 1  \n",
    "I : 1   -> F\n",
    "I : 0   -> I\n",
    "F : 0|1 -> F\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"226pt\" height=\"118pt\"\n",
       " viewBox=\"0.00 0.00 226.00 118.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 114)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-114 222,-114 222,4 -4,4\"/>\n",
       "<!-- EMPTY -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>EMPTY</title>\n",
       "</g>\n",
       "<!-- I -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>I</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"109\" cy=\"-22\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-18.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">I</text>\n",
       "</g>\n",
       "<!-- EMPTY&#45;&gt;I -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>EMPTY&#45;&gt;I</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.3048,-22C62.6909,-22 71.9407,-22 80.4103,-22\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.5976,-25.5001 90.5976,-22 80.5976,-18.5001 80.5976,-25.5001\"/>\n",
       "</g>\n",
       "<!-- I&#45;&gt;I -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>I&#45;&gt;I</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M102.6208,-39.0373C101.3189,-48.8579 103.4453,-58 109,-58 112.4717,-58 114.6042,-54.4289 115.3975,-49.3529\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"118.8971,-49.031 115.3792,-39.0373 111.8971,-49.0435 118.8971,-49.031\"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-61.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- F -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>F</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"196\" cy=\"-22\" rx=\"18\" ry=\"18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"196\" cy=\"-22\" rx=\"22\" ry=\"22\"/>\n",
       "<text text-anchor=\"middle\" x=\"196\" y=\"-18.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">F</text>\n",
       "</g>\n",
       "<!-- I&#45;&gt;F -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>I&#45;&gt;F</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M127.0265,-22C137.6806,-22 151.4825,-22 163.9377,-22\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"163.9848,-25.5001 173.9847,-22 163.9847,-18.5001 163.9848,-25.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"150.5\" y=\"-25.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- F&#45;&gt;F -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>F&#45;&gt;F</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M191.9395,-43.8066C191.5527,-53.5625 192.9063,-62 196,-62 197.9336,-62 199.1874,-58.7041 199.7614,-53.8504\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"203.2612,-53.9064 200.0605,-43.8066 196.2643,-53.698 203.2612,-53.9064\"/>\n",
       "<text text-anchor=\"middle\" x=\"196\" y=\"-65.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- F&#45;&gt;F -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>F&#45;&gt;F</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M189.0597,-43.1143C185.9952,-61.0956 188.3086,-80 196,-80 202.2493,-80 204.9482,-67.5201 204.0969,-53.1954\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"207.5574,-52.6501 202.9403,-43.1143 200.603,-53.4481 207.5574,-52.6501\"/>\n",
       "<text text-anchor=\"middle\" x=\"196\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x103f423c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotObj_dfa(DFA_E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def step_dfa(D, q, c):\n",
    "    \"\"\"In : D (consistent DFA)\n",
    "            q (state in D)\n",
    "            c (symbol in D's sigma)\n",
    "       Out: next state of q via c (state in D) \n",
    "    \"\"\"\n",
    "    assert(c in D[\"Sigma\"]), \"step_dfa given c not in Sigma.\"\n",
    "    assert(q in D[\"Q\"]), \"step_dfa given q not in Q.\"\n",
    "    return D[\"Delta\"][(q,c)]\n",
    "\n",
    "def run_dfa(D, s):\n",
    "    \"\"\"In : D (consistent DFA)\n",
    "            q (state in D)\n",
    "            s (string over D's sigma, including \"\")\n",
    "       Out: next state of q via s (state in D) \n",
    "    \"\"\"    \n",
    "    state = D[\"q0\"]\n",
    "    while s != \"\":\n",
    "        state = step_dfa(D, state, s[0])\n",
    "        s = s[1:]\n",
    "    return state\n",
    "\n",
    "def accepts_dfa(D, s):\n",
    "    \"\"\"In : D (consistent DFA)\n",
    "            s (string over D's sigma, including \"\")\n",
    "       Out: Boolean (if state after s-run is in D's final).\n",
    "    \"\"\"\n",
    "    return run_dfa(D, s) in D[\"F\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepts_dfa(DFA_E1, \"001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepts_dfa(DFA_B0, \"000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFA_B0_and_E1 = intersect_dfa(DFA_B0, DFA_E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"383pt\" height=\"255pt\"\n",
       " viewBox=\"0.00 0.00 382.98 254.69\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 250.6943)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-250.6943 378.9839,-250.6943 378.9839,4 -4,4\"/>\n",
       "<!-- EMPTY -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>EMPTY</title>\n",
       "</g>\n",
       "<!-- \\(I_I\\) -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>\\(I_I\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"118.2976\" cy=\"-91.1972\" rx=\"27.0966\" ry=\"27.0966\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.2976\" y=\"-87.4972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(I_I)</text>\n",
       "</g>\n",
       "<!-- EMPTY&#45;&gt;\\(I_I\\) -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>EMPTY&#45;&gt;\\(I_I\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.3923,-91.1972C62.6976,-91.1972 71.9683,-91.1972 80.8159,-91.1972\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.9247,-94.6973 90.9246,-91.1972 80.9246,-87.6973 80.9247,-94.6973\"/>\n",
       "</g>\n",
       "<!-- \\(B_F\\) -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>\\(B_F\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"225.0923\" cy=\"-148.1972\" rx=\"32.4942\" ry=\"32.4942\"/>\n",
       "<text text-anchor=\"middle\" x=\"225.0923\" y=\"-144.4972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_F)</text>\n",
       "</g>\n",
       "<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M220.0347,-180.7378C220.1369,-190.796 221.8227,-198.6943 225.0923,-198.6943 227.1357,-198.6943 228.5606,-195.609 229.3668,-190.8395\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"232.8664,-190.9785 230.1498,-180.7378 225.8873,-190.4374 232.8664,-190.9785\"/>\n",
       "<text text-anchor=\"middle\" x=\"225.0923\" y=\"-202.4943\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M215.6403,-179.5484C213.4514,-198.6329 216.602,-216.6943 225.0923,-216.6943 232.0569,-216.6943 235.4285,-204.5406 235.207,-189.6382\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"238.6923,-189.2975 234.5443,-179.5484 231.7073,-189.7563 238.6923,-189.2975\"/>\n",
       "<text text-anchor=\"middle\" x=\"225.0923\" y=\"-220.4943\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(F_I\\) -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>\\(F_I\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"225.0923\" cy=\"-35.1972\" rx=\"29.4969\" ry=\"29.4969\"/>\n",
       "<text text-anchor=\"middle\" x=\"225.0923\" y=\"-31.4972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_I)</text>\n",
       "</g>\n",
       "<!-- \\(F_I\\)&#45;&gt;\\(F_I\\) -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>\\(F_I\\)&#45;&gt;\\(F_I\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M215.0068,-62.8596C214.5586,-73.555 217.9204,-82.4446 225.0923,-82.4446 229.7988,-82.4446 232.8645,-78.6162 234.2893,-72.9614\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"237.7881,-73.1278 235.1777,-62.8596 230.815,-72.5145 237.7881,-73.1278\"/>\n",
       "<text text-anchor=\"middle\" x=\"225.0923\" y=\"-86.2446\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- \\(F_F\\) -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>\\(F_F\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"339.7866\" cy=\"-35.1972\" rx=\"31.373\" ry=\"31.373\"/>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"339.7866\" cy=\"-35.1972\" rx=\"35.3956\" ry=\"35.3956\"/>\n",
       "<text text-anchor=\"middle\" x=\"339.7866\" y=\"-31.4972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_F)</text>\n",
       "</g>\n",
       "<!-- \\(F_I\\)&#45;&gt;\\(F_F\\) -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>\\(F_I\\)&#45;&gt;\\(F_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M254.6289,-35.1972C266.5699,-35.1972 280.6334,-35.1972 293.8536,-35.1972\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"294.2184,-38.6973 304.2184,-35.1972 294.2184,-31.6973 294.2184,-38.6973\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.0894\" y=\"-38.9972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(I_I\\)&#45;&gt;\\(B_F\\) -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>\\(I_I\\)&#45;&gt;\\(B_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M142.5309,-104.1314C155.7815,-111.2037 172.4882,-120.1206 187.4009,-128.0801\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"185.9373,-131.2662 196.4074,-132.8871 189.2334,-125.0907 185.9373,-131.2662\"/>\n",
       "<text text-anchor=\"middle\" x=\"169.0952\" y=\"-122.9972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(I_I\\)&#45;&gt;\\(F_I\\) -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>\\(I_I\\)&#45;&gt;\\(F_I\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M142.5309,-78.49C156.6267,-71.0986 174.6336,-61.6563 190.2314,-53.4772\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.8581,-56.5763 199.089,-48.8326 188.6073,-50.3769 191.8581,-56.5763\"/>\n",
       "<text text-anchor=\"middle\" x=\"169.0952\" y=\"-70.9972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M334.3611,-69.9887C334.523,-80.34 336.3315,-88.3945 339.7866,-88.3945 342,-88.3945 343.5377,-85.0889 344.3996,-79.9915\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"347.8909,-80.2393 345.2122,-69.9887 340.9139,-79.6725 347.8909,-80.2393\"/>\n",
       "<text text-anchor=\"middle\" x=\"339.7866\" y=\"-92.1945\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M329.509,-68.8919C327.4115,-88.3141 330.8374,-106.3945 339.7866,-106.3945 347.1278,-106.3945 350.7522,-94.228 350.6599,-79.1346\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"354.139,-78.6718 350.0642,-68.8919 347.1508,-79.0783 354.139,-78.6718\"/>\n",
       "<text text-anchor=\"middle\" x=\"339.7866\" y=\"-110.1945\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x103f7a518>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotObj_dfa(DFA_B0_and_E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFA_B0_or_E1 = union_dfa(DFA_B0, DFA_E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"391pt\" height=\"267pt\"\n",
       " viewBox=\"0.00 0.00 390.98 266.69\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 262.6943)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-262.6943 386.9839,-262.6943 386.9839,4 -4,4\"/>\n",
       "<!-- EMPTY -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>EMPTY</title>\n",
       "</g>\n",
       "<!-- \\(I_I\\) -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>\\(I_I\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"118.2976\" cy=\"-95.1972\" rx=\"27.0966\" ry=\"27.0966\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.2976\" y=\"-91.4972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(I_I)</text>\n",
       "</g>\n",
       "<!-- EMPTY&#45;&gt;\\(I_I\\) -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>EMPTY&#45;&gt;\\(I_I\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.3923,-95.1972C62.6976,-95.1972 71.9683,-95.1972 80.8159,-95.1972\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.9247,-98.6973 90.9246,-95.1972 80.9246,-91.6973 80.9247,-98.6973\"/>\n",
       "</g>\n",
       "<!-- \\(B_F\\) -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>\\(B_F\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"229.0923\" cy=\"-156.1972\" rx=\"32.4945\" ry=\"32.4945\"/>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"229.0923\" cy=\"-156.1972\" rx=\"36.4942\" ry=\"36.4942\"/>\n",
       "<text text-anchor=\"middle\" x=\"229.0923\" y=\"-152.4972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_F)</text>\n",
       "</g>\n",
       "<!-- \\(I_I\\)&#45;&gt;\\(B_F\\) -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>\\(I_I\\)&#45;&gt;\\(B_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M142.3384,-108.4333C155.7453,-115.8148 172.8058,-125.2077 188.2439,-133.7074\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.6581,-136.8297 197.1063,-138.5868 190.0343,-130.6977 186.6581,-136.8297\"/>\n",
       "<text text-anchor=\"middle\" x=\"169.0952\" y=\"-128.9972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(F_I\\) -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>\\(F_I\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"229.0923\" cy=\"-35.1972\" rx=\"29.4667\" ry=\"29.4667\"/>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"229.0923\" cy=\"-35.1972\" rx=\"33.4967\" ry=\"33.4967\"/>\n",
       "<text text-anchor=\"middle\" x=\"229.0923\" y=\"-31.4972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_I)</text>\n",
       "</g>\n",
       "<!-- \\(I_I\\)&#45;&gt;\\(F_I\\) -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>\\(I_I\\)&#45;&gt;\\(F_I\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M142.3384,-82.1781C156.3838,-74.572 174.4389,-64.7943 190.4378,-56.1303\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.4475,-59.0223 199.5741,-51.1825 189.114,-52.8669 192.4475,-59.0223\"/>\n",
       "<text text-anchor=\"middle\" x=\"169.0952\" y=\"-74.9972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M223.676,-192.3585C223.8884,-202.7114 225.6938,-210.6943 229.0923,-210.6943 231.2694,-210.6943 232.7927,-207.4181 233.6623,-202.3414\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"237.1513,-202.6184 234.5085,-192.3585 230.1763,-202.0271 237.1513,-202.6184\"/>\n",
       "<text text-anchor=\"middle\" x=\"229.0923\" y=\"-214.4943\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M218.7377,-191.2574C216.8048,-210.7471 220.2563,-228.6943 229.0923,-228.6943 236.3405,-228.6943 239.9655,-216.6174 239.9673,-201.519\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"243.449,-201.0673 239.4469,-191.2574 236.4579,-201.4219 243.449,-201.0673\"/>\n",
       "<text text-anchor=\"middle\" x=\"229.0923\" y=\"-232.4943\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(F_F\\) -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>\\(F_F\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"347.7866\" cy=\"-35.1972\" rx=\"31.373\" ry=\"31.373\"/>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"347.7866\" cy=\"-35.1972\" rx=\"35.3956\" ry=\"35.3956\"/>\n",
       "<text text-anchor=\"middle\" x=\"347.7866\" y=\"-31.4972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_F)</text>\n",
       "</g>\n",
       "<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M342.3611,-69.9887C342.523,-80.34 344.3315,-88.3945 347.7866,-88.3945 350,-88.3945 351.5377,-85.0889 352.3996,-79.9915\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"355.8909,-80.2393 353.2122,-69.9887 348.9139,-79.6725 355.8909,-80.2393\"/>\n",
       "<text text-anchor=\"middle\" x=\"347.7866\" y=\"-92.1945\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M337.509,-68.8919C335.4115,-88.3141 338.8374,-106.3945 347.7866,-106.3945 355.1278,-106.3945 358.7522,-94.228 358.6599,-79.1346\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"362.139,-78.6718 358.0642,-68.8919 355.1508,-79.0783 362.139,-78.6718\"/>\n",
       "<text text-anchor=\"middle\" x=\"347.7866\" y=\"-110.1945\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- \\(F_I\\)&#45;&gt;\\(F_F\\) -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>\\(F_I\\)&#45;&gt;\\(F_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M262.4711,-35.1972C274.807,-35.1972 289.0074,-35.1972 302.2389,-35.1972\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"302.5886,-38.6973 312.5885,-35.1972 302.5885,-31.6973 302.5886,-38.6973\"/>\n",
       "<text text-anchor=\"middle\" x=\"289.0894\" y=\"-38.9972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(F_I\\)&#45;&gt;\\(F_I\\) -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>\\(F_I\\)&#45;&gt;\\(F_I\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M218.2199,-66.7249C218.1049,-77.6344 221.729,-86.4446 229.0923,-86.4446 233.9244,-86.4446 237.1463,-82.6504 238.7578,-76.9585\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"242.2693,-77.066 239.9646,-66.7249 235.3174,-76.2461 242.2693,-77.066\"/>\n",
       "<text text-anchor=\"middle\" x=\"229.0923\" y=\"-90.2446\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x103e83ef0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotObj_dfa(DFA_B0_or_E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"274pt\" height=\"147pt\"\n",
       " viewBox=\"0.00 0.00 273.59 146.99\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 142.9942)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-142.9942 269.5894,-142.9942 269.5894,4 -4,4\"/>\n",
       "<!-- EMPTY -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>EMPTY</title>\n",
       "</g>\n",
       "<!-- \\(I_I\\) -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>\\(I_I\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"118.2976\" cy=\"-36.4971\" rx=\"27.0966\" ry=\"27.0966\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.2976\" y=\"-32.7971\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(I_I)</text>\n",
       "</g>\n",
       "<!-- EMPTY&#45;&gt;\\(I_I\\) -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>EMPTY&#45;&gt;\\(I_I\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.3923,-36.4971C62.6976,-36.4971 71.9683,-36.4971 80.8159,-36.4971\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.9247,-39.9972 90.9246,-36.4971 80.9246,-32.9972 80.9247,-39.9972\"/>\n",
       "</g>\n",
       "<!-- \\(B_F\\) -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>\\(B_F\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"229.0923\" cy=\"-36.4971\" rx=\"32.4945\" ry=\"32.4945\"/>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"229.0923\" cy=\"-36.4971\" rx=\"36.4942\" ry=\"36.4942\"/>\n",
       "<text text-anchor=\"middle\" x=\"229.0923\" y=\"-32.7971\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_F)</text>\n",
       "</g>\n",
       "<!-- \\(I_I\\)&#45;&gt;\\(B_F\\) -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>\\(I_I\\)&#45;&gt;\\(B_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M145.685,-36.4971C156.699,-36.4971 169.7174,-36.4971 182.1535,-36.4971\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"182.406,-39.9972 192.406,-36.4971 182.406,-32.9972 182.406,-39.9972\"/>\n",
       "<text text-anchor=\"middle\" x=\"169.0952\" y=\"-40.2971\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(I_I\\)&#45;&gt;\\(B_F\\) -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>\\(I_I\\)&#45;&gt;\\(B_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.1287,-24.0084C149.6284,-21.3218 156.7397,-18.8767 163.5952,-17.4971 171.0201,-16.003 178.8239,-16.4419 186.3537,-17.9411\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"185.4815,-21.3306 196.0397,-20.4493 187.2364,-14.5541 185.4815,-21.3306\"/>\n",
       "<text text-anchor=\"middle\" x=\"169.0952\" y=\"-21.2971\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M223.676,-72.6583C223.8884,-83.0113 225.6938,-90.9942 229.0923,-90.9942 231.2694,-90.9942 232.7927,-87.718 233.6623,-82.6413\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"237.1513,-82.9183 234.5085,-72.6583 230.1763,-82.327 237.1513,-82.9183\"/>\n",
       "<text text-anchor=\"middle\" x=\"229.0923\" y=\"-94.7942\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M218.7377,-71.5573C216.8048,-91.0469 220.2563,-108.9942 229.0923,-108.9942 236.3405,-108.9942 239.9655,-96.9173 239.9673,-81.8189\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"243.449,-81.3672 239.4469,-71.5573 236.4579,-81.7218 243.449,-81.3672\"/>\n",
       "<text text-anchor=\"middle\" x=\"229.0923\" y=\"-112.7942\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x103ea71d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotObj_dfa(min_dfa(DFA_B0_or_E1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## DFA complementation\n",
    "\n",
    "DFA complementation works by flipping the final and non-final states. We must check that the DFA is totalized before we embark on that, as the 'black-hole' state will now become 'white-hole' (a final state from which all symbols lead back to itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def comp_dfa(D):\n",
    "    \"\"\"In : D (DFA : partially consistent)\n",
    "       Out: Consistent DFA that is D's complement.\n",
    "       Before we begin, make D total. This is crucial, \n",
    "       as the black-hole states if any\n",
    "       become \"white-hole\" states in the complemented DFA \n",
    "       (i.e. really turn into accepting \n",
    "       states from which one can't get out).\n",
    "       Then flip the FINAL and NON-FINAL states.\n",
    "    \"\"\"\n",
    "    Dtot = totalize_dfa(D)\n",
    "    return mk_dfa(D[\"Q\"],D[\"Sigma\"],D[\"Delta\"],D[\"q0\"],D[\"Q\"]-D[\"F\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFA_comp_B0_or_E1 = comp_dfa(DFA_B0_or_E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"383pt\" height=\"251pt\"\n",
       " viewBox=\"0.00 0.00 382.98 250.69\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 246.6943)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-246.6943 378.9839,-246.6943 378.9839,4 -4,4\"/>\n",
       "<!-- EMPTY -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>EMPTY</title>\n",
       "</g>\n",
       "<!-- \\(I_I\\) -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>\\(I_I\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122.2976\" cy=\"-87.1972\" rx=\"27.1222\" ry=\"27.1222\"/>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122.2976\" cy=\"-87.1972\" rx=\"31.0965\" ry=\"31.0965\"/>\n",
       "<text text-anchor=\"middle\" x=\"122.2976\" y=\"-83.4972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(I_I)</text>\n",
       "</g>\n",
       "<!-- EMPTY&#45;&gt;\\(I_I\\) -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>EMPTY&#45;&gt;\\(I_I\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.0536,-87.1972C62.3696,-87.1972 71.722,-87.1972 80.7745,-87.1972\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.7965,-90.6973 90.7964,-87.1972 80.7964,-83.6973 80.7965,-90.6973\"/>\n",
       "</g>\n",
       "<!-- \\(B_F\\) -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>\\(B_F\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"233.0923\" cy=\"-144.1972\" rx=\"32.4942\" ry=\"32.4942\"/>\n",
       "<text text-anchor=\"middle\" x=\"233.0923\" y=\"-140.4972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_F)</text>\n",
       "</g>\n",
       "<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M228.0347,-176.7378C228.1369,-186.796 229.8227,-194.6943 233.0923,-194.6943 235.1357,-194.6943 236.5606,-191.609 237.3668,-186.8395\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"240.8664,-186.9785 238.1498,-176.7378 233.8873,-186.4374 240.8664,-186.9785\"/>\n",
       "<text text-anchor=\"middle\" x=\"233.0923\" y=\"-198.4943\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M223.6403,-175.5484C221.4514,-194.6329 224.602,-212.6943 233.0923,-212.6943 240.0569,-212.6943 243.4285,-200.5406 243.207,-185.6382\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"246.6923,-185.2975 242.5443,-175.5484 239.7073,-185.7563 246.6923,-185.2975\"/>\n",
       "<text text-anchor=\"middle\" x=\"233.0923\" y=\"-216.4943\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(F_F\\) -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>\\(F_F\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"343.7866\" cy=\"-31.1972\" rx=\"31.3957\" ry=\"31.3957\"/>\n",
       "<text text-anchor=\"middle\" x=\"343.7866\" y=\"-27.4972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_F)</text>\n",
       "</g>\n",
       "<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M338.7254,-62.4244C338.7773,-72.4492 340.4644,-80.3945 343.7866,-80.3945 345.863,-80.3945 347.3007,-77.2908 348.0996,-72.5157\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"351.5988,-72.6559 348.8479,-62.4244 344.6179,-72.1382 351.5988,-72.6559\"/>\n",
       "<text text-anchor=\"middle\" x=\"343.7866\" y=\"-84.1945\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M334.4186,-61.2553C332.0683,-80.2328 335.1909,-98.3945 343.7866,-98.3945 350.8378,-98.3945 354.2061,-86.1733 353.8915,-71.3057\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"357.3765,-70.9726 353.1546,-61.2553 350.3953,-71.4845 357.3765,-70.9726\"/>\n",
       "<text text-anchor=\"middle\" x=\"343.7866\" y=\"-102.1945\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- \\(F_I\\) -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>\\(F_I\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"233.0923\" cy=\"-31.1972\" rx=\"29.4969\" ry=\"29.4969\"/>\n",
       "<text text-anchor=\"middle\" x=\"233.0923\" y=\"-27.4972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_I)</text>\n",
       "</g>\n",
       "<!-- \\(F_I\\)&#45;&gt;\\(F_F\\) -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>\\(F_I\\)&#45;&gt;\\(F_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M262.4657,-31.1972C274.5952,-31.1972 288.8772,-31.1972 302.0599,-31.1972\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"302.3345,-34.6973 312.3344,-31.1972 302.3344,-27.6973 302.3345,-34.6973\"/>\n",
       "<text text-anchor=\"middle\" x=\"289.0894\" y=\"-34.9972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(F_I\\)&#45;&gt;\\(F_I\\) -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>\\(F_I\\)&#45;&gt;\\(F_I\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M223.0068,-58.8596C222.5586,-69.555 225.9204,-78.4446 233.0923,-78.4446 237.7988,-78.4446 240.8645,-74.6162 242.2893,-68.9614\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"245.7881,-69.1278 243.1777,-58.8596 238.815,-68.5145 245.7881,-69.1278\"/>\n",
       "<text text-anchor=\"middle\" x=\"233.0923\" y=\"-82.2446\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- \\(I_I\\)&#45;&gt;\\(B_F\\) -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>\\(I_I\\)&#45;&gt;\\(B_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M150.2558,-101.5807C163.7179,-108.5065 180.0723,-116.9203 194.6817,-124.4364\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"193.4889,-127.7586 203.9823,-129.2212 196.6912,-121.5341 193.4889,-127.7586\"/>\n",
       "<text text-anchor=\"middle\" x=\"177.0952\" y=\"-120.9972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(I_I\\)&#45;&gt;\\(F_I\\) -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>\\(I_I\\)&#45;&gt;\\(F_I\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M150.2558,-73.0661C164.5893,-65.8213 182.2018,-56.9193 197.4956,-49.1892\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"199.3226,-52.1875 206.6686,-44.5528 196.1649,-45.9401 199.3226,-52.1875\"/>\n",
       "<text text-anchor=\"middle\" x=\"177.0952\" y=\"-64.9972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x103f87048>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotObj_dfa(DFA_comp_B0_or_E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFA_comp_compB0_or_compE1 = comp_dfa(union_dfa(comp_dfa(DFA_B0), comp_dfa(DFA_E1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"383pt\" height=\"255pt\"\n",
       " viewBox=\"0.00 0.00 382.98 254.69\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 250.6943)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-250.6943 378.9839,-250.6943 378.9839,4 -4,4\"/>\n",
       "<!-- EMPTY -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>EMPTY</title>\n",
       "</g>\n",
       "<!-- \\(I_I\\) -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>\\(I_I\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"118.2976\" cy=\"-91.1972\" rx=\"27.0966\" ry=\"27.0966\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.2976\" y=\"-87.4972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(I_I)</text>\n",
       "</g>\n",
       "<!-- EMPTY&#45;&gt;\\(I_I\\) -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>EMPTY&#45;&gt;\\(I_I\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M54.3923,-91.1972C62.6976,-91.1972 71.9683,-91.1972 80.8159,-91.1972\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.9247,-94.6973 90.9246,-91.1972 80.9246,-87.6973 80.9247,-94.6973\"/>\n",
       "</g>\n",
       "<!-- \\(B_F\\) -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>\\(B_F\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"225.0923\" cy=\"-148.1972\" rx=\"32.4942\" ry=\"32.4942\"/>\n",
       "<text text-anchor=\"middle\" x=\"225.0923\" y=\"-144.4972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_F)</text>\n",
       "</g>\n",
       "<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M220.0347,-180.7378C220.1369,-190.796 221.8227,-198.6943 225.0923,-198.6943 227.1357,-198.6943 228.5606,-195.609 229.3668,-190.8395\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"232.8664,-190.9785 230.1498,-180.7378 225.8873,-190.4374 232.8664,-190.9785\"/>\n",
       "<text text-anchor=\"middle\" x=\"225.0923\" y=\"-202.4943\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M215.6403,-179.5484C213.4514,-198.6329 216.602,-216.6943 225.0923,-216.6943 232.0569,-216.6943 235.4285,-204.5406 235.207,-189.6382\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"238.6923,-189.2975 234.5443,-179.5484 231.7073,-189.7563 238.6923,-189.2975\"/>\n",
       "<text text-anchor=\"middle\" x=\"225.0923\" y=\"-220.4943\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(F_I\\) -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>\\(F_I\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"225.0923\" cy=\"-35.1972\" rx=\"29.4969\" ry=\"29.4969\"/>\n",
       "<text text-anchor=\"middle\" x=\"225.0923\" y=\"-31.4972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_I)</text>\n",
       "</g>\n",
       "<!-- \\(F_I\\)&#45;&gt;\\(F_I\\) -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>\\(F_I\\)&#45;&gt;\\(F_I\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M215.0068,-62.8596C214.5586,-73.555 217.9204,-82.4446 225.0923,-82.4446 229.7988,-82.4446 232.8645,-78.6162 234.2893,-72.9614\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"237.7881,-73.1278 235.1777,-62.8596 230.815,-72.5145 237.7881,-73.1278\"/>\n",
       "<text text-anchor=\"middle\" x=\"225.0923\" y=\"-86.2446\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- \\(F_F\\) -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>\\(F_F\\)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"339.7866\" cy=\"-35.1972\" rx=\"31.373\" ry=\"31.373\"/>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"339.7866\" cy=\"-35.1972\" rx=\"35.3956\" ry=\"35.3956\"/>\n",
       "<text text-anchor=\"middle\" x=\"339.7866\" y=\"-31.4972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_F)</text>\n",
       "</g>\n",
       "<!-- \\(F_I\\)&#45;&gt;\\(F_F\\) -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>\\(F_I\\)&#45;&gt;\\(F_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M254.6289,-35.1972C266.5699,-35.1972 280.6334,-35.1972 293.8536,-35.1972\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"294.2184,-38.6973 304.2184,-35.1972 294.2184,-31.6973 294.2184,-38.6973\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.0894\" y=\"-38.9972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(I_I\\)&#45;&gt;\\(B_F\\) -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>\\(I_I\\)&#45;&gt;\\(B_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M142.5309,-104.1314C155.7815,-111.2037 172.4882,-120.1206 187.4009,-128.0801\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"185.9373,-131.2662 196.4074,-132.8871 189.2334,-125.0907 185.9373,-131.2662\"/>\n",
       "<text text-anchor=\"middle\" x=\"169.0952\" y=\"-122.9972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(I_I\\)&#45;&gt;\\(F_I\\) -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>\\(I_I\\)&#45;&gt;\\(F_I\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M142.5309,-78.49C156.6267,-71.0986 174.6336,-61.6563 190.2314,-53.4772\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.8581,-56.5763 199.089,-48.8326 188.6073,-50.3769 191.8581,-56.5763\"/>\n",
       "<text text-anchor=\"middle\" x=\"169.0952\" y=\"-70.9972\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M334.3611,-69.9887C334.523,-80.34 336.3315,-88.3945 339.7866,-88.3945 342,-88.3945 343.5377,-85.0889 344.3996,-79.9915\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"347.8909,-80.2393 345.2122,-69.9887 340.9139,-79.6725 347.8909,-80.2393\"/>\n",
       "<text text-anchor=\"middle\" x=\"339.7866\" y=\"-92.1945\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n",
       "</g>\n",
       "<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M329.509,-68.8919C327.4115,-88.3141 330.8374,-106.3945 339.7866,-106.3945 347.1278,-106.3945 350.7522,-94.228 350.6599,-79.1346\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"354.139,-78.6718 350.0642,-68.8919 347.1508,-79.0783 354.139,-78.6718\"/>\n",
       "<text text-anchor=\"middle\" x=\"339.7866\" y=\"-110.1945\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x103f87ba8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotObj_dfa(DFA_comp_compB0_or_compE1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## DFA Union\n",
    "\n",
    "DFA union has a straightforward definition as in the book. We march the DFAs in tandem. We accept if either DFA accepts_dfa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def union_dfa(D1in, D2in):\n",
    "    \"\"\"In : D1in (consistent DFA)\n",
    "            D2in (consistent DFA)\n",
    "       Out: DFA for language union of D1in, D2in (consistent DFA). \n",
    "    \"\"\"\n",
    "    assert(is_consistent_dfa(D1in)), \"Inconsist. DFA1 in union_dfa\"\n",
    "    assert(is_consistent_dfa(D2in)), \"Inconsist. DFA2 in union_dfa\"\n",
    "    if (D1in[\"Sigma\"] != D2in[\"Sigma\"]):\n",
    "        print(\"Union on DFA with different alphabets.\")\n",
    "        print(\"Making alphabets the same (taking unions).\")\n",
    "        Sigma = D1in[\"Sigma\"] | D2in[\"Sigma\"]\n",
    "        D1   = copy.deepcopy(D1in)\n",
    "        D2   = copy.deepcopy(D2in)\n",
    "        D1[\"Sigma\"] = Sigma\n",
    "        D2[\"Sigma\"] = Sigma\n",
    "        D1 = totalize_dfa(D1)\n",
    "        D2 = totalize_dfa(D2)\n",
    "    else:\n",
    "        D1 = totalize_dfa(D1in)\n",
    "        D2 = totalize_dfa(D2in)\n",
    "   \n",
    "    # The states can be anything in the cartesian product\n",
    "    Q     = set(product(D1[\"Q\"], D2[\"Q\"]))\n",
    "    \n",
    "    # Accept if one of the DFAs accepts\n",
    "    F     = (set(product(D1[\"F\"], D2[\"Q\"])) | \n",
    "             set(product(D1[\"Q\"], D2[\"F\"])))\n",
    "    \n",
    "    # Start a lock-step march from the respective q0\n",
    "    q0    = (D1[\"q0\"], D2[\"q0\"])\n",
    "    \n",
    "    # The transition function attempts to march both\n",
    "    # DFAs in lock-step per their own transition functions\n",
    "    Delta = { ((q1,q2),ch) : (q1p, q2p) \n",
    "               for q1 in D1[\"Q\"] for q1p in D1[\"Q\"] \n",
    "               for q2 in D2[\"Q\"] for q2p in D2[\"Q\"] \n",
    "               for ch in D1[\"Sigma\"] \n",
    "               if D1[\"Delta\"][(q1,ch)] == q1p and\n",
    "                  D2[\"Delta\"][(q2,ch)] == q2p }\n",
    "                                                          \n",
    "    return pruneUnreach(\n",
    "        mk_dfa(Q, D1[\"Sigma\"], Delta, q0, F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def intersect_dfa(D1in, D2in):\n",
    "    \"\"\"In : D1in (consistent DFA)\n",
    "            D2in (consistent DFA)\n",
    "       Out: DFA for language intersection of D1in, D2in (consistent DFA). \n",
    "    \"\"\"\n",
    "    assert(is_consistent_dfa(D1in)), \"Inconsist. DFA1 in intersect_dfa\"\n",
    "    assert(is_consistent_dfa(D2in)), \"Inconsist. DFA2 in intersect_dfa\"\n",
    "    if (D1in[\"Sigma\"] != D2in[\"Sigma\"]):\n",
    "        print(\"Intersection on DFA with different alphabets.\")\n",
    "        print(\"Making alphabets the same (taking unions).\")\n",
    "        Sigma = D1in[\"Sigma\"] | D2in[\"Sigma\"]\n",
    "        D1   = copy.deepcopy(D1in)\n",
    "        D2   = copy.deepcopy(D2in)\n",
    "        D1[\"Sigma\"] = Sigma\n",
    "        D2[\"Sigma\"] = Sigma\n",
    "        D1 = totalize_dfa(D1)\n",
    "        D2 = totalize_dfa(D2)\n",
    "    else:\n",
    "        D1 = totalize_dfa(D1in)\n",
    "        D2 = totalize_dfa(D2in)\n",
    " \n",
    "    Q     = set(product(D1[\"Q\"], D2[\"Q\"]))\n",
    "    \n",
    "    # This is the only difference with the union:\n",
    "    # The final states are those when both DFA accept\n",
    "    F     = set(product(D1[\"F\"], D2[\"F\"]))\n",
    "           \n",
    "    q0    = (D1[\"q0\"], D2[\"q0\"])\n",
    "    Delta = { ((q1,q2),ch) : (q1p, q2p) \n",
    "               for q1 in D1[\"Q\"] for q1p in D1[\"Q\"] \n",
    "               for q2 in D2[\"Q\"] for q2p in D2[\"Q\"] \n",
    "               for ch in D1[\"Sigma\"] \n",
    "               if D1[\"Delta\"][(q1,ch)] == q1p and\n",
    "                  D2[\"Delta\"][(q2,ch)] == q2p }\n",
    "                                                          \n",
    "    return pruneUnreach(\n",
    "        mk_dfa(Q, D1[\"Sigma\"], Delta, q0, F))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Eliminating unreachable states\n",
    "\n",
    "Let us write the code for eliminating unreachable states. Function pruneUnreach(DFA) returns a new DFA with unreachable states in the input DFA removed (all transitions from them are also removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def pruneUnreach(D):\n",
    "    \"\"\"In : D (consistent DFA)\n",
    "       Out: Consistent DFA.\n",
    "       Given a consistent (and of course total) DFA D,\n",
    "       returns a new (consistent) DFA with unreachable \n",
    "       states in D removed. Transitions from each unreachable \n",
    "       state are also removed. Reachable states are those that\n",
    "       can be reached in |D[\"Q\"]| - 1 steps or less.\n",
    "    \"\"\"\n",
    "    Nsteps   = len(D[\"Q\"]) - 1 # Search this far\n",
    "    Frontier = set({D[\"q0\"]})  # BFS frontier\n",
    "    AccumF   = Frontier        # Used to accumulate Frontier changes\n",
    "    for n in range(Nsteps):\n",
    "        for q in Frontier:\n",
    "            for ch in D[\"Sigma\"]:\n",
    "                AccumF = AccumF | set({step_dfa(D, q, ch)})\n",
    "        Frontier = AccumF\n",
    "        \n",
    "    newQ     = Frontier\n",
    "    newF     = D[\"F\"] & Frontier\n",
    "    newDelta = dict({ ((q,ch),qp) \n",
    "                      for ((q,ch),qp) in fn_trans(D[\"Delta\"]) \n",
    "                      if q in Frontier })\n",
    "    return mk_dfa(Frontier, D[\"Sigma\"], newDelta, D[\"q0\"], newF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# DFA Isomorphism\n",
    "\n",
    "This routine is handy to check whether two DFA are isomorphic. Given they are rooted at q0, the isomorphism-check is linear in the number of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def iso_dfa(D1,D2):\n",
    "    \"\"\"Given consistent and total DFAs D1 and D2,\n",
    "       check whether they are isomorphic. Two DFAs\n",
    "       are isomorphic if they have the same number\n",
    "       of states and are language-equivalent. (One would\n",
    "       then be able to match-up state for state and transition\n",
    "       for transition.)\n",
    "    \"\"\"\n",
    "    assert(is_consistent_dfa(D1)), \"Inconsist. DFA1 in iso_dfa\"\n",
    "    assert(is_consistent_dfa(D2)), \"Inconsist. DFA2 in iso_dfa\"\n",
    "    return (len(D1[\"Q\"]) == len(D2[\"Q\"]) and\n",
    "            langeq_dfa(D1, D2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def langeq_dfa(D1, D2, gen_counterex=False):\n",
    "    \"\"\"Given consistent and total DFAs D1 and D2,\n",
    "       check whether they are language-equivalent. \n",
    "       gen_counterex is a flag that triggers the\n",
    "        printing of a counter-example showing the\n",
    "        pairs that were marched in tandem till a\n",
    "        difference was found.\n",
    "        \n",
    "       Two DFAs are language-equivalent if they \n",
    "       accept the same set of strings. We determine\n",
    "       this through a joint depth-first walk of the \n",
    "       two DFAs until we detect a difference (return\n",
    "       False then) or all pairs of states have been\n",
    "       visited (return True then).\n",
    "    \"\"\"\n",
    "    if D1[\"Sigma\"] != D2[\"Sigma\"]:\n",
    "        print(\"The DFA cannot be compared, as their\", end=\"\")\n",
    "        print(\" alphabets are different; namely:\")\n",
    "        print(\"Sigma1 = \", D1[\"Sigma\"])\n",
    "        print(\"Sigma2 = \", D2[\"Sigma\"])\n",
    "        return False\n",
    "    else:\n",
    "        (eqStatus, cex_path) = h_langeq_dfa(D1[\"q0\"], D1,\n",
    "                                            D2[\"q0\"], D2, \n",
    "                                            Visited=[])\n",
    "        if not eqStatus:\n",
    "            if gen_counterex:\n",
    "                print(\"The DFA are NOT language equivalent!\")\n",
    "                print(\"Path leading to counterexample is: \")\n",
    "                print(cex_path)\n",
    "        return eqStatus # True or False\n",
    "\n",
    "def same_status(q1, D1, q2, D2):\n",
    "    \"\"\"Check if q1,q2 are both accepting\n",
    "       or both non-accepting wrt D1,D2 resply.\n",
    "    \"\"\"\n",
    "    return (q1 in D1[\"F\"]) == (q2 in D2[\"F\"])\n",
    "\n",
    "def h_langeq_dfa(q1, D1, q2, D2, Visited):\n",
    "    \"\"\"Helper for langeq_dfa. \n",
    "       If (q1,q2) is in Visited, no screw-up so far, so\n",
    "        continue. Else if they agree in status, recursively\n",
    "        check for all reachable configurations (a DFS in\n",
    "        recursion). Else (if they differ in status),\n",
    "        then return (False, Visited) where the latter is\n",
    "        the counter-example trace.  \n",
    "    \"\"\"\n",
    "    if (q1,q2) in Visited:\n",
    "        return (True, Visited)\n",
    "    else:\n",
    "        extVisited = Visited + [(q1,q2)]\n",
    "        if not same_status(q1,D1,q2,D2):\n",
    "            return (False, extVisited)\n",
    "        else:\n",
    "            l_nxt_status = list(\n",
    "            map(lambda symb:\n",
    "                h_langeq_dfa(D1[\"Delta\"][(q1,symb)], D1,\n",
    "                             D2[\"Delta\"][(q2,symb)], D2,\n",
    "                             extVisited),\n",
    "                D1[\"Sigma\"]))\n",
    "            l_rejects = list(filter(lambda x: x[0]==False, l_nxt_status))\n",
    "            if l_rejects==[]:\n",
    "                return (True, extVisited)\n",
    "            else:\n",
    "                return l_rejects[0] # which is the first offending (status,cex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langeq_dfa( DFA_comp_compB0_or_compE1 , DFA_B0_and_E1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso_dfa( DFA_comp_compB0_or_compE1 , DFA_B0_and_E1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_DFA_B0_or_E1 = min_dfa(DFA_B0_or_E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langeq_dfa(DFA_B0_or_E1, min_DFA_B0_or_E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso_dfa(DFA_B0_or_E1, min_DFA_B0_or_E1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# DFA Minimization\n",
    "\n",
    "This is a good juncture at which to introduce DFA minimization. \n",
    "\n",
    "## Definition of DFA minimization\n",
    "\n",
    "We define minimization only for consistent DFA.\n",
    " \n",
    "> _A consistent DFA D is minimal if it satisfies two properties_\n",
    " \n",
    ">  1. There should not be any unreachable states (from the start state) in it\n",
    " \n",
    ">  2. For any pair of distinct states $(s_1,s_2)$ in $D$, we must not have the case that for all strings $s$ in $\\Sigma^*$, $\\hat{\\delta}(s_1,s) = \\hat{\\delta}(s_2,s)$.\n",
    "\n",
    "\n",
    "We don't want useless states and we don't want redundant states. For instance, let me make a redundant DFA with duplicate states, below. Then you can easily see how even bloated DFAs can recognize the same language. After seeing this fact, we will introduce you to a DFA minimization algorithm.\n",
    "\n",
    "First, let's learn how to deliberately bloat a DFA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## DFA minimization algorithm (high level)\n",
    "\n",
    "Having seen two examples of bloated DFA, we now define a minimization algorithm. Here is the gist. The actual algorithm is in the code that follows.\n",
    "\n",
    "1. Put the states into two equivalence classes (EC):\n",
    "\n",
    " a. All non-final states are in one EC, say NF\n",
    " b. All final states are in another EC, say F\n",
    " c. We call any (sa,sb) such that sa in NF and sb in F as **zero-distinguishable** states, as \n",
    "    a $\\varepsilon$ string can distinguish sa and sb (meaning, when sa is evolved through $\\varepsilon$ or $sb$ is evolved through $\\varepsilon$, the resulting state is the same -- sa or sb)\n",
    "    \n",
    "     * \"Evolved through\" means $\\hat{\\delta}(sa,\\varepsilon) = sa$, and similarly for sb\n",
    "     \n",
    "     * In our example DFA d34bl, IF is zero-distinguishable from all other states\n",
    " \n",
    "2. In general, we have $k$-distinguishable states for $k>0$ (above step discussed $k=0$ as zero-distinguishability)\n",
    "\n",
    "3. Split states:\n",
    " \n",
    " a. Take a state pair $(s_1,s_2)$ such that they are not $k$ distinguishable.\n",
    " b. Take $c\\in\\Sigma$\n",
    " c. If $\\delta(s_1,c) = sn_1$ and $\\delta(s_2,c) = sn_2$ and $(sn_1,sn_2)$ are $k$-distinguishable, mark $(s_1,s_2)$ as $k+1$-distinguishable. \n",
    " \n",
    "4. Repeat the above process till across one sweep, the distinguishability relation does not change.\n",
    "\n",
    "5. Take all maximal sets of pairs of states that have not been found distinguishable yet. Pick a representative from each such maximal set. These states are in the final DFA. \n",
    "\n",
    "6. Go by the state transitions of the representative states. (The remaining states in the equivalence classes are not necessary.)\n",
    "\n",
    "  * In our example, all pairs in $\\{A,A1\\} \\times \\{B,B1\\}$ will be 1-distinguishable (distinction made by $0$)\n",
    "  \n",
    "  * The final equivalence classes will be $\\{IF\\}$, and then $\\{A,A1\\}$, and $\\{B,B1\\}$.\n",
    "  \n",
    "\n",
    "<span style=\"color:blue\"> **Clearly, the above algorithm cannot make full sense till you see how it can be worked out \"by hand\" using some pictures. This is what we will now do before showing you the actual code.\n",
    "\n",
    "** </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## A fully worked-out example\n",
    "\n",
    "<font size=\"3\"> \n",
    "\n",
    "This is the initial display of a matrix (only the lower half shown, as the upper half is symmetric). The matrix shows \".\" which are points at which state pairs \"collide.\" The dots in this figure allow for these pairs to collide (we show pairs only one way, i.e. (P,Q) and not the other way i.e. (Q,P) also).\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "<font size=\"4\"> \n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "A   .\n",
    "\n",
    "A1  .   .\n",
    "\n",
    "B   .   .   .\n",
    "\n",
    "B1  .   .   .   .\n",
    "\n",
    "    IF  A   A1  B\n",
    "    \n",
    "The above is a convenient arrangement to talk about these pairs:\n",
    "\n",
    "\n",
    "(A, IF),\n",
    "\n",
    "(A1, IF), (A1, A)\n",
    "\n",
    "(B, IF),  (B, A),  (B, A1)\n",
    "\n",
    "(B1, IF), (B1, A), (B1, A1), (B1, B)\n",
    "\n",
    "Now, here is how the computation proceeds for this example:\n",
    "===========================================================\n",
    "\n",
    "Frame-0              Frame-1                Frame-2                \n",
    " \n",
    "A   -1                A   0                  A   0                 \n",
    "\n",
    "A1  -1   -1           A1  0   -1             A1  0   -1            \n",
    " \n",
    "B   -1   -1  -1       B   0   -1   -1        B   0   1   1         \n",
    "\n",
    "B1  -1   -1  -1  -1   B1  0   -1   -1  -1    B1  0   1   1   -1    \n",
    "\n",
    "    IF   A   A1  B        IF  A    A1  B         IF  A   A1  B         \n",
    "    \n",
    "    \n",
    "Frame-3 = Frame-2   \n",
    "\n",
    "A   0 \n",
    "\n",
    "A1  0   -1\n",
    "\n",
    "B   0   1   1\n",
    "\n",
    "B1  0   1   1   -1\n",
    "\n",
    "    IF  A   A1  B   \n",
    "``` \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Let's see another example as well. We will explain the second \n",
    "example (we leave the above example wrt **D34bl** as something you can explain.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "\n",
    "Now, here is how the computation proceeds for this example:\n",
    "-------------------------------------------------------- \n",
    " \n",
    " <br>\n",
    " \n",
    "<font size=\"3\"> \n",
    "\n",
    "\n",
    "```\n",
    " \n",
    "Frame-0                  Frame-1                   Frame-2                    \n",
    "                                                                                                     \n",
    "S2  -1                   S2   0                    S2   0                     \n",
    "\n",
    "S3  -1  -1               S3   0  -1                S3   0  -1                 \n",
    "\n",
    "S4  -1  -1  -1           S4  -1   0   0            S4   2   0   0             \n",
    "\n",
    "S5  -1  -1  -1  -1       S5  -1   0   0  -1        S5   2   0   0  -1         \n",
    "\n",
    "S6  -1  -1  -1  -1  -1   S6   0  -1  -1   0   0    S6   0   1   1   0   0     \n",
    "\n",
    "    S1  S2  S3  S4  S5       S1  S2  S3  S4  S5        S1  S2  S3  S4  S5        \n",
    "\n",
    "Initial                  0-distinguishable         1-distinguishable                         \n",
    "     \n",
    "     \n",
    "Frame-3                 Frame-4     \n",
    "                        =\n",
    "                        Frame-3\n",
    "\n",
    "S2   0\n",
    "\n",
    "S3   0  -1\n",
    "\n",
    "S4   2   0   0\n",
    "\n",
    "S5   2   0   0  -1\n",
    "\n",
    "S6   0   1   1   0   0\n",
    "\n",
    "    S1  S2  S3  S4  S5\n",
    "    \n",
    "2-distinguishable \n",
    "     \n",
    "```\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Here is the algorithm, going frame by frame.\n",
    "\n",
    "- Initial Frame: \n",
    "\n",
    "     The initial frame is drawn to clash all _combinations_ of states taken two at a time.\n",
    "     Since we have 6 states, we have $6\\choose 2$ = $15$ entries. We put a -1 against each\n",
    "     such pair to denote that they have not been found distinguishable yet.\n",
    "\n",
    "- Frame *0-distinguishable*: We now put a 0 where a pair of states is 0-distinguishable. This means the states are distinguisable after consuming $\\varepsilon$. This of course means that the states are themselves distinguishable. This is only possible if one is a final state and the other is not (in that case, one state, after consuming $\\varepsilon$ accepts_dfa, and another state after consuming $\\varepsilon$ does not accept.\n",
    "\n",
    "  - So for instance, notice that (S3,S1) and (S4,S2) are 0-distinguishable, meaning that one is a final and the other is a non-final state.\n",
    "\n",
    "- Frame *1-distinguishable*: We now put a 1 where a pair of states is 1-distinguishable. This means the states are distinguisable after consuming a string of length $1$ (a single symbol). This is only possible if one state transitions to a final state and the other transitions to a non-final state after consuming a member of $\\Sigma$. \n",
    "\n",
    "  State pairs (S6,S2) and (S6,S3) are of this kind. While both S6 and S2 are final states (hence _0-indistinguishable_), after consuming an 'a' (or a 'b') they respectively go to a final/non-final state.\n",
    " This means that\n",
    "\n",
    "  - after processing **the same symbol** one state -- let's say pre_p -- finds itself landing in a state p and another state  -- let's say pre_q -- finds itself landing in a state q such that (p,q) is 0-distinguishable.\n",
    "  \n",
    "  - When this happens, states pre-p and pre-q are **1-distinguishable**.\n",
    "\n",
    "- Frame *2-distinguishable*: We now put a 2 where a pair of states is 2-distinguishable. This means the states are distinguisable after consuming a string of length $2$ (a string of length $2$). This is only possible if one state transitions to a state (say p) and the other transitions to state (say q) after consuming a member of $\\Sigma$ such that (p,q) is **1-distinguishable**. State pairs (S5,S1) and (S4,S1) are 2-distinguishable because\n",
    "\n",
    "  - after processing **the same symbol** one state -- let's say pre_p -- finds itself landing in a state p and another state  -- let's say pre_q -- finds itself landing in a state q such that (p,q) is 0-distinguishable.\n",
    "  \n",
    "  - When this happens, states pre-p and pre-q are **1-distinguishable**.\n",
    "  \n",
    "  - One example is this:\n",
    "  \n",
    "    - S5 and S1 are 2-distinguishable.\n",
    "    \n",
    "    - This is because after seeing an 'aa', S1 lands in a non-final state while S5 lands in a final state\n",
    "    \n",
    "    - Observe that \"aa\" = \"a\" + \"a\" . Thus, after eating the first \"a\", S1 lands in S2 while S5 lands in S6, and (S2,S6) have already been deemed 1-distinguishable.\n",
    "    \n",
    "    - Thus, when we mark (S5,S1) as 2-distinguishable, we are sending the matrix entry at (S5,S2) from \n",
    "      -1 to 2\n",
    " \n",
    "\n",
    "\n",
    "  - Now, in search of 3-distinguishability, we catch hold of all pairs in the matrix and see if we can send another -1 entry to \"3\". This appears not to happen. \n",
    "  \n",
    "     - Thus, if (S2,S3) is pushed via any sequence of symbols (any string) of any length, it\n",
    "       always stays in the same type of state. Thus, after seeing 'ababba', S2 is in S6, while S3 \n",
    "        is also in S6.\n",
    "\n",
    "\n",
    " - Thus, given no changes in the matrix, we stop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Code for DFA minimization\n",
    "\n",
    "We now provide the code for DFA minimization, referring to the above narrative to keep us focused as to which part of the algorithm we are implementing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### The heart of the algorithm is function fixptDist. This seeks the fixpoint (or \"fixed-point\") of the Dist (or Distinguishability) relation. Neat eh?\n",
    "\n",
    "A fixpoint of a function f is a value x such that f(x) = x. In our case, the functiion in question is one that take the entire matrix (frame) and tries to spit out the next matrix (frame). When we get a matrix m such that f(m) = m, the matrix has stabilized.\n",
    "\n",
    "In our case, we obtain a fixpoint of the function with respect to input value \"ht\" (hash-table) representing our matrix. We also pass along the DFA in question (\"D\") that is a read-only argument (to consult its transition function, etc).\n",
    "\n",
    "See how the code speaks for itself:\n",
    "\n",
    "* We set \"changed = True\" outside a while loop, and enter this loop \"while changed\".\n",
    "\n",
    "* We set changed = False, hoping to get out\n",
    "\n",
    "  - Any change-causing activity (n-distinguishability for some n) will set changed back to True\n",
    "  \n",
    "  - If not, we will \"get out of the jail\"\n",
    "  \n",
    "  - Termination is guaranteed. Why?\n",
    "    \n",
    "      * There are only a finite number of states\n",
    "      \n",
    "      * If we pump a long-enough string from a pair of states,\n",
    "      \n",
    "          - Clearly, it can try to meander, visiting fresh state pairs that are m-distinguishable for \n",
    "             an m <= n (those other state pairs and their distinguishability distance\n",
    "             were generated in an earlier pass or the current pass)\n",
    "             \n",
    "      * In short, for any pair of states (p,q), there is a maximal (loop-free) string s such that \n",
    "        $\\hat{\\delta}(p,s) \\in F$ while $\\hat{\\delta}(q,s)\\in (Q\\setminus F)$. This is the highest the \n",
    "        distinguishability number can get to.\n",
    "             \n",
    "           - If $s$ has a loop, there is a shorter string that establishes the distinguishability \n",
    "              number.\n",
    "         \n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "We now go through all aspects of the code:\n",
    "\n",
    "* We first iterate across \"kv\" (key,value) pairs in ht.items(), i.e. we iterate through all \n",
    "  the matrix entries (pairs) which are recorded in \"ht\" (the hash table). The value recorded is the\n",
    "  distinguishability number.\n",
    "  \n",
    "* We obtain s0 and s1, the states that this hash-table entry is modeling.\n",
    "\n",
    "* We iterate across all $c\\in\\Sigma$\n",
    "\n",
    "* We obtain the next state after sending s0 and s1 via $c$\n",
    "\n",
    "* If we land in the same next state (ns0 == ns1), we continue (try to \"get out of the jail\" by not\n",
    "  resetting changed)\n",
    "  \n",
    "* If this is a visited pair (i.e. (ns0,ns1) in ht), then\n",
    "\n",
    "  - If one is \"-1\" while the other is >= 0  (meaning they are distinguishable states)\n",
    "     \n",
    "       - then we set changed = True, and continue, breaking this iteration of the \"for c\"\n",
    "       \n",
    "       - else we examine it as pair (ns1, ns0). This is because \"ht\" does not store both \n",
    "          (ns0,ns1) and (ns1,ns0). But we have to check both ways\n",
    "          \n",
    "       - we apply the same logic\n",
    "       \n",
    "* If we can find distinguishability, we increase the ht number\n",
    "\n",
    "* else we will get out of the loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def fixptDist(D, ht):\n",
    "    \"\"\"In : D (consistent DFA)\n",
    "            ht (hash-table of distinguishability pair distances)\n",
    "       Out: ht that has attained a fixpoint in distinguishability.\n",
    "       Helper (but main workhorse) for min_dfa.\n",
    "       Given an initial hash-table ht and a DFA D to be minimized,\n",
    "       determine the min. distinguishability distances, going frame \n",
    "       by frame, as illustrated in the DFA minimization algorithm. \n",
    "       Return fixpoint ht. Fixpoint is when ht ceases to change.\n",
    "    \"\"\"\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for kv in ht.items():\n",
    "            s0 = kv[0][0]\n",
    "            s1 = kv[0][1]\n",
    "            for c in D[\"Sigma\"]:\n",
    "                ns0 = D[\"Delta\"][(s0,c)]\n",
    "                ns1 = D[\"Delta\"][(s1,c)]\n",
    "                #\n",
    "                # Distinguishable state pairs carry \n",
    "                # \"distinguishability distance\" in the ht\n",
    "                if ns0 == ns1:\n",
    "                    continue\n",
    "                if (ns0, ns1) in ht:\n",
    "                    # s0,s1 are distinguishable\n",
    "                    if ht[(s0,s1)] == -1 and ht[(ns0, ns1)] >= 0: \n",
    "                        # acquire one more than the\n",
    "                        # dist. number of (ns0,ns1)\n",
    "                        ht[(s0,s1)] = ht[(ns0, ns1)] + 1          \n",
    "                        changed = True                            \n",
    "                        break\n",
    "                else:\n",
    "                    # ht stores only (ns0,ns1); \n",
    "                    # so check the other way\n",
    "                    if (ns1, ns0) in ht:                              \n",
    "                        if ht[(s0,s1)] == -1 and ht[(ns1, ns0)] >= 0:  \n",
    "                            ht[(s0,s1)] = ht[(ns1, ns0)] + 1           \n",
    "                            changed = True                             \n",
    "                            break                                      \n",
    "                    else:                                              \n",
    "                        print(\"ht doesn't cover all reqd state combos.\")\n",
    "    return ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def min_dfa(D, state_name_mode='succinct'):  # Default state mode\n",
    "    \"\"\"In : D (consistent DFA to be minimized)\n",
    "       Out: Minimized version of D.\n",
    "       The top-level callable DFA minimizer.\n",
    "       Given a DFA D, go through the state minimization algorithm.\n",
    "       state_name_mode is 'verbose' or 'succinct', producing two \n",
    "       variants, as you can guess.\n",
    "       If the state_name_mode is verbose, we will make state names\n",
    "       by stringing together the state names in the equivalence\n",
    "       classes. Else we keep the name of the representative of \n",
    "       eqch equivalence class.\n",
    "    \"\"\"\n",
    "    if (len(D[\"Q\"]) == 1): # Already minimal\n",
    "        return D\n",
    "    else:\n",
    "        # Build a dict of all state combinations of DFA.\n",
    "        # Function state_combos also imparts a -1 for each state pair,\n",
    "        # initializing the separation distance at -1.  \n",
    "        ht = dict(state_combos(list(D[\"Q\"])))\n",
    "    \n",
    "        # Mark final and non-final states to be 0-distinguishable.\n",
    "        # This is achieved by putting a 0 against those state pairs.\n",
    "        sepFinNonFin(D, ht)\n",
    "    \n",
    "        # Main fixpoint computation: Assigning distinguishability dist. \n",
    "        #==============================================================\n",
    "        ht = fixptDist(D, ht)\n",
    "    \n",
    "        # Pick out equivalent state-pairs, i.e. those that cannot be \n",
    "        # distinguished. These are still with a \"-1\" in ht.\n",
    "        ht_1 = [ stpair for (stpair, dist) in ht.items() if dist == -1 ]\n",
    "    \n",
    "        # Now form equivalence classes\n",
    "        # what's returned is \n",
    "        # [(rep_1, [all_eql_states_1]), (rep_2, [all_eql_states_2]),...]\n",
    "        # which includes all equivalence classes of size 2 or more.\n",
    "        rep_eqc = bash_eql_classes(ht_1)\n",
    "\n",
    "        # Now we have to deal with singleton equivalence classes. \n",
    "        # These sit unmerged, OUTSIDE OF ALL (x,y) in ht_1\n",
    "        # i.e. all the entries in ht_1 are PARTNERED STATE PAIRS.  \n",
    "    \n",
    "        # If we now take D[\"Q\"] and subtract from it all those x and y\n",
    "        # which are present in some pair in ht_1, we obtain completely\n",
    "        # non-mergable states. These are states in their own eql. classes.\n",
    "    \n",
    "        # 1. Find all partnered states from ht_1\n",
    "        Partnered_states = list({x for (x,y) in ht_1} |\n",
    "                                {y for (x,y) in ht_1})\n",
    "    \n",
    "        # 2. Now who is left un-partnered?\n",
    "        List_of_self_only_eqlt_states = listminus(D[\"Q\"], Partnered_states)                     \n",
    "    \n",
    "        # 3. For these singletons, i.e. \"self-only equivalent states\", \n",
    "        # they are self-representative. Form pairs that indicate this fact.\n",
    "        rep_eqc_1 = [(x, [x]) for x in List_of_self_only_eqlt_states]\n",
    "    \n",
    "        # 4. OK now, we can combine the set of pairs where each pair is \n",
    "        # (representative, [the list of equivalent states])\n",
    "        # So finally we get the list of equivalence classes with \n",
    "        # representatives  which is of this form:\n",
    "        # [(a0,[a0, a1, a2, a3, a4]), (b0,[b0, b1]), (c0,[c0]), ...] \n",
    "        final_rep_eqc = rep_eqc + rep_eqc_1\n",
    "    \n",
    "        # We are now ready to build a DFA out of final_rep_eqc. \n",
    "        # =====================================================\n",
    "    \n",
    "        # 1. First, form the set of minimized states, which are \n",
    "        # state representatives.\n",
    "        minQ = {x for (x,y) in final_rep_eqc}\n",
    "    \n",
    "        # 2. The Alpbahet remains the same.\n",
    "        minSigma = D[\"Sigma\"]\n",
    "    \n",
    "        # 3. The starting state is the representative of D[\"q0\"]\n",
    "        minq0 = q0_of(D[\"q0\"], final_rep_eqc)\n",
    "    \n",
    "        # 4. The final states are the representatives of the original\n",
    "        #    final states. This is computed by helper F_of.\n",
    "        minF = F_of(D[\"F\"], final_rep_eqc)\n",
    "    \n",
    "        # 5. The transition relation of the minimized DFA is obtained\n",
    "        #    by the helper Delta_of\n",
    "        minDelta = Delta_of(D[\"Delta\"], final_rep_eqc)\n",
    "    \n",
    "        # 6. We now need to rename the states if the user wants verbose \n",
    "        #    names (default is succinct). Verbose names are the name of \n",
    "        #    states in each equivalence class strung together sep by \"_\".\n",
    "        if state_name_mode == 'verbose':\n",
    "            # First build a state-renaming hash-table involving \n",
    "            # mk_state_eqc_name\n",
    "            state_rename_ht = { x : mk_state_eqc_name(y) \n",
    "                                for (x,y) in final_rep_eqc }\n",
    "        \n",
    "            minQ            = { state_rename_ht[x] for x in minQ }\n",
    "            minq0           = state_rename_ht[minq0]\n",
    "            minF            = { state_rename_ht[f] for f in minF }\n",
    "            minDelta = { (state_rename_ht[x], y) : state_rename_ht[z] \n",
    "                         for ((x,y),z) in minDelta.items() }\n",
    "        #\n",
    "        # Return the finished (minimized) DFA!\n",
    "        return mk_dfa(minQ, minSigma, minDelta, minq0, minF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def pairFR(L):\n",
    "    \"\"\"In : L (list of states)\n",
    "       Out: List of pairs with L[0] paired with each state in L[1:],\n",
    "            with the distinguishability distance initialized to -1.\n",
    "       Helper for generating state_combos.\n",
    "    \"\"\"\n",
    "    return list(map(lambda x: ((L[0], x), -1), L[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def state_combos(L):\n",
    "    \"\"\"In : L (list of states)\n",
    "       Out: List of combinations of L's states (rep. as pairs),\n",
    "            with distinguishability distances marked as -1. \n",
    "       Helper for min_dfa.\n",
    "       Given a list of DFA states L (assume length >= 2),\n",
    "       Form state combinations, paired up as (L[i], L[i+1]).\n",
    "       This forms the 'ht' that is acted upon by fixptDist.\n",
    "    \"\"\"\n",
    "    if len(L) <= 2:\n",
    "        return([((L[0], L[1]), -1)])\n",
    "    else:\n",
    "        return (pairFR(L)) + (state_combos(L[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def sepFinNonFin(D, ht):\n",
    "    \"\"\"In : D (consistent DFA)\n",
    "            ht (hash table of distinguishability distances)\n",
    "       Out: ht with (nonfinal,final) pairs in ht\n",
    "            marked with a distinguishability distance of 0.\n",
    "       Helper for min_dfa.\n",
    "       Given a hash-table of separation distances and a DFA D,\n",
    "       mark each state pair (final,non-final) with value 0\n",
    "       indicating their 0-distinguishability.\n",
    "    \"\"\"\n",
    "    # Form a separation predicate \n",
    "    sepPred = lambda x,y: (x in D[\"F\"] and y in (D[\"Q\"] - D[\"F\"]) or \n",
    "                           y in D[\"F\"] and x in (D[\"Q\"] - D[\"F\"]))\n",
    "                         \n",
    "    # Now separate all states where sepPred holds\n",
    "    for kv in ht.items():\n",
    "        if sepPred(kv[0][0], kv[0][1]):\n",
    "            # Mark that this pair is 0-distinguishable\n",
    "            ht[kv[0]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def bash_eql_classes(eql_reln):\n",
    "    \"\"\"In : eql_reln (equivalence relation : list of pairs of states).\n",
    "       Out: List of equivalence classes with representatives.\n",
    "            I.e. a structure of the form\n",
    "            [ (state0, [state0, state1, state2,]), ... ]\n",
    "            where state0 is a representative for the three (for example)\n",
    "            equivalent states state0, state1, state2. There are as many\n",
    "            such pairs as equivalence classes.\n",
    "       Helper for min_dfa.\n",
    "       Given an Eql. reln. of the form \n",
    "       [(a,b),(a,c),(d,e),(f,h),(g,f),..].\n",
    "       1. Grow eql classes \n",
    "       2. Elect a representative for each eql class\n",
    "       3. Return \"equivalence classes with representatives.\"\n",
    "       This is a structure of the form\n",
    "        [(a0,[a0, a1, a2, a3, a4]), (b0,[b0, b1]), (c0,[c0]), ...] \n",
    "       where \"a0\" is a state and a0,a1,a2,a3,a4 are equivalent to it\n",
    "       The same goes for the bs, cs, etc.\n",
    "    \"\"\"\n",
    "    return bash_1(eql_reln, []) # seed with empty list of eql class sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def listminus(L1, L2):\n",
    "    \"\"\"In : L1 : list or set\n",
    "            L2 : list or set\n",
    "       Out: List of items in L1 that are not in L2.\n",
    "       Helper for min_dfa and bash_1. Implements subtraction (L1 - L2).\n",
    "    \"\"\"\n",
    "    return [x for x in L1 if x not in L2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def bash_1(eql_reln, L_eq_classes):\n",
    "    \"\"\"In : eql_reln (equivalence relation : list of pairs of eqlt states)\n",
    "            L_eq_classes (list of eql classes which are SETS of states \n",
    "            for now.)\n",
    "       Out: return list of equivalence classes with representatives.\n",
    "       Helper for bash_eql_classes. \n",
    "       1) eql_reln is the current equivalence relation \n",
    "          (list of pairs)\n",
    "       2) L_eq_classes is a list of sets that are the eqlt \n",
    "          classes coalesced thus far.\n",
    "       3) We remove one pair at a time from the eql_reln and find\n",
    "          existing equivalence classes to expand, thus modifying\n",
    "          L_eq_classes each time. \n",
    "       Once the equivalence relation is emptied, we call mk_rep_eqc\n",
    "       thus making a list of equivalence classes with representatives\n",
    "       of the form \n",
    "       [(a0,[a0, a1, a2, a3, a4]), (b0,[b0, b1]), (c0,[c0]), ...]. \n",
    "    \"\"\"\n",
    "    if eql_reln == []:\n",
    "        # When we have fully processed the given equivalence \n",
    "        # relation, return a list of equivalence classes with \n",
    "        # representatives of the form \n",
    "        # [(a0,[a0, a1, a2, a3, a4]), (b0,[b0, b1]), (c0,[c0]), ...]\n",
    "        return mk_rep_eqc(L_eq_classes)\n",
    "    else:\n",
    "        # pick the next pair from the eql_reln being coalesced\n",
    "        eq0 = eql_reln[0]   \n",
    "        a = eq0[0]          \n",
    "        b = eq0[1]   \n",
    "        \n",
    "        # We know that a is a state that is equivalent to b, since\n",
    "        # they exist as a pair in eql_reln[0].\n",
    "        \n",
    "        # Now we must see if 'a' already lives in a COALESCED \n",
    "        # equivalence class\n",
    "   \n",
    "        # Set Sa is a typical equivalence class in L_eq_classes\n",
    "        # See if 'a' is in Sa.\n",
    "        \n",
    "        SaL = [Sa for Sa in L_eq_classes if a in Sa]\n",
    "        \n",
    "        # There must be zero or one such set as Sa. \n",
    "        # Thus, |SaL| = 0 or 1\n",
    "        \n",
    "        # Similarly, see which (if any) eql class that b lives in\n",
    "        SbL = [Sb for Sb in L_eq_classes if b in Sb]  \n",
    "        \n",
    "        # Now there are four cases:\n",
    "        \n",
    "        # 1. a,b pair is totally new (not in any eql. class so far)\n",
    "        if (SaL == [] and SbL == []):\n",
    "            # Add a fresh eql class {a,b} to L_eq_classes and recurse\n",
    "            return bash_1(eql_reln[1:], [{a,b}] + L_eq_classes)\n",
    "        \n",
    "        # 2. a is in eql class SaL[0] while b is not in any eql class\n",
    "        elif (SbL == [] and not(SaL == [])):\n",
    "            # Remove the little eql. class in which 'a' sits\n",
    "            # replace by a bigger eql. class that now also includes 'b'. \n",
    "            # That is, we must invite 'b' into the same eql class \n",
    "            # in which 'a' sits (this being SaL[0]).\n",
    "            \n",
    "            # Then we take away the eql class that 'a' sits in from \n",
    "            # L_eq_classes, and of course replace it with an expanded \n",
    "            # version that includes b\n",
    "            New_L_eq_classes = (listminus(L_eq_classes, SaL) +\n",
    "                                [SaL[0] | {b}])\n",
    "            \n",
    "            return bash_1(eql_reln[1:], New_L_eq_classes)\n",
    "        \n",
    "        # 3. b is in eql class SbL[0] while a is not in any eql class\n",
    "        elif (SaL == [] and not(SbL == [])):\n",
    "            # Similar steps as above, with 'a' being invited in.\n",
    "            \n",
    "            New_L_eq_classes = (listminus(L_eq_classes, SbL) +\n",
    "                                [SbL[0] | {a}])\n",
    "            \n",
    "            return bash_1(eql_reln[1:], New_L_eq_classes)\n",
    "        \n",
    "        else:\n",
    "            # a and b are both in their own little eql. classes\n",
    "            # We must now collapse both the eql classes into a huge one\n",
    "            # Remove both little pre-existing eql. classes. Replace \n",
    "            # with union-ed one. Neither 'a' nor 'b' is being invited in\n",
    "            # afresh; rather, the eql classes they are in \n",
    "            # (i.e. SaL[0],SbL[0]) are being merged.\n",
    "            \n",
    "            New_L_eq_classes = (listminus(L_eq_classes,SaL+SbL) + \n",
    "                                [SaL[0] | SbL[0]])\n",
    "            \n",
    "            return bash_1(eql_reln[1:], New_L_eq_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def mk_rep_eqc(L_eq_classes):\n",
    "    \"\"\"Helper for bash_1 that finds the representative of a set of\n",
    "       equivalent states. Given the final equivalence classes,\n",
    "       make representatives for each; stick the repr. at the \n",
    "       head of a pair. Thus, (repr, eql-class-with-repr) list\n",
    "       is returned.\n",
    "    \"\"\"\n",
    "    Ll = list(map(lambda x: list(x), L_eq_classes))\n",
    "    return list(map(lambda x: (x[0], x), Ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def F_of(F, final_rep_eqc):\n",
    "    \"\"\"In : F (final states of DFA)\n",
    "            final_rep_eqc : equivalence class with representatives\n",
    "       Out: A set of representatives of the final states \n",
    "       Helper for min_dfa.\n",
    "       Given F, the final states of a DFA and final equivalence\n",
    "       classes with representatives of the form \n",
    "       [(rep,[states eql to rep], ...)\n",
    "       obtain those equivalence classes in which the original final \n",
    "       states live. Form a set of the representatives of these states. \n",
    "       This will be the set of representatives of the final states.\n",
    "    \"\"\"\n",
    "    return { x for (x,X) in final_rep_eqc \n",
    "             if not (set(F) & set(X)) == set({}) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def rep_of_s(s, final_rep_eqc):\n",
    "    \"\"\"Helper for min_dfa. Given a list \n",
    "       [(rep_of_s1, [states_eql_to_s1]),...]\n",
    "       that has states paired with the list of equivalent states, \n",
    "       return the representative of s.\n",
    "    \"\"\"\n",
    "    if final_rep_eqc == []:\n",
    "        print(\"Error, did not find a rep for state s\")\n",
    "    else:\n",
    "        x_X = final_rep_eqc[0]\n",
    "        if s in x_X[1]:\n",
    "            return x_X[0]\n",
    "        else:\n",
    "            return q0_of(s, final_rep_eqc[1:])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def q0_of(q0, final_rep_eqc):\n",
    "    \"\"\"Helper for min_dfa. Given the initial state of the DFA and\n",
    "       the list [(rep, [eql states]), ...], find the representative\n",
    "       of q0 in lieu of q0.\n",
    "    \"\"\"\n",
    "    return rep_of_s(q0, final_rep_eqc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def Delta_of(Delta, final_rep_of_eqc):\n",
    "    \"\"\"In : Delta (transition function of the given DFA)\n",
    "            final_rep_of_eqc (eql classes with representatives)\n",
    "       Out: Form a dict of representatives' moves.\n",
    "       Helper for min_dfa. \n",
    "       Given the original transition function Delta and the\n",
    "       list [(rep_of_eqc, [equivalent states,...]), ...], \n",
    "       produce a new transition function with state representatives \n",
    "       (not the original states) jumping around!\n",
    "       The nice thing is that if multiple states had jumped around, \n",
    "       their transitions AUTOMATICALLY GET MERGED when we pool \n",
    "       the transitions into a hash-table (dictionary). Thus, we are \n",
    "       merging transitions among equivalent states also.\n",
    "    \"\"\"\n",
    "    return { (rep_of_s(s0, final_rep_of_eqc), a): \n",
    "              rep_of_s(s1, final_rep_of_eqc)  \n",
    "              for  ((s0,a),s1) in Delta.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def mk_state_eqc_name(L):\n",
    "    \"\"\"In : List of states (in each eql class)\n",
    "       Out: single state names by bashing the states separated by \"_\".\n",
    "       Helper for min_dfa. \n",
    "       Given a list of states, bash the \n",
    "       state names together separated by an underscore. \n",
    "       This is useful when 'verbose mode' state name printing \n",
    "       is desired.\n",
    "    \"\"\"\n",
    "    return \"_\".join(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "318px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
